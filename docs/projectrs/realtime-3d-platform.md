---
sidebar_position: 1
---

# Real-time 3D Platform Case Study

AI ê¸°ë°˜ ì‹¤ì‹œê°„ 3D ì‹œê°í™” í”Œë«í¼ êµ¬ì¶• ê²½í—˜

## ğŸ“‹ Project Overview

### Challenge

ë¸Œë¼ìš°ì €ì—ì„œ ê³ í’ˆì§ˆ 3D í™˜ê²½ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²½í—˜í•˜ê³ , AI ê¸°ë°˜ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆëŠ” í”Œë«í¼ êµ¬ì¶•

### Constraints

- íƒ€ì„ë¼ì¸: 5ê°œì›” (MVP)
- íŒ€ ê·œëª¨: Tech Lead + Frontend 2ëª…
- ì˜ˆì‚°: ì¤‘ì†Œ ê·œëª¨ ìŠ¤íƒ€íŠ¸ì—…
- ê¸°ìˆ  ë¶€ì±„: ì—†ìŒ (greenfield project)

### Solution

Unreal Engine 5.5 Pixel Streaming + AI RAG ì‹œìŠ¤í…œ + Modular Monolithic Backend

## ğŸ—ï¸ Technical Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Frontend (Next.js)                â”‚
â”‚  - 3D WebRTC viewer                         â”‚
â”‚  - AI chat interface                        â”‚
â”‚  - Partner matching UI                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â”‚   Nginx     â”‚
        â”‚   Proxy     â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”“
    â”ƒ                    â”ƒ
â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STB Service   â”‚  â”‚  PLB Service â”‚
â”‚  (Streaming)   â”‚  â”‚  (Platform)  â”‚
â”‚                â”‚  â”‚              â”‚
â”‚  - Session     â”‚  â”‚  - Auth      â”‚
â”‚  - Routing     â”‚  â”‚  - AI RAG    â”‚
â”‚  - WebRTC      â”‚  â”‚  - Matching  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                     â”‚
     â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚   MySQL     â”‚
     â”‚              â”‚   Redis     â”‚
     â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UE5 Instances â”‚
â”‚  (Containers)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer          | Technology        | Reason                    |
| -------------- | ----------------- | ------------------------- |
| Frontend       | Next.js + React   | SSR, Image optimization   |
| Styling        | Tailwind CSS      | Rapid development         |
| Backend        | Node.js + Express | Team expertise, async I/O |
| Database       | MySQL + Prisma    | ACID + Type safety        |
| Cache          | Redis             | Session management        |
| 3D Engine      | Unreal Engine 5.5 | Photorealistic quality    |
| Streaming      | WebRTC + Cirrus   | Low latency               |
| AI             | FastAPI + OpenAI  | Python ecosystem          |
| Vector DB      | Pinecone          | Managed solution          |
| Infrastructure | Docker + Nginx    | Containerization          |
| Cloud          | Multi-cloud       | Cost optimization         |

## ğŸ¯ Key Technical Challenges

### Challenge 1: GPU Bottleneck

**Problem:**

- Single user consuming 100% GPU
- Unstable FPS (10-60 fluctuating)
- Multi-user support impossible

**Investigation:**

```bash
# Hypothesis testing
1. Lower resolution? â†’ GPU 90% (not main issue)
2. Reduce quality? â†’ GPU 85% (marginal)
3. Check rendering loop? â†’ Unlimited FPS! (FOUND IT)
```

**Solution:**

```bash
# Force 30 FPS limit
t.MaxFPS 30

# Enable DLSS
r.NGX.DLSS.Enable 1
r.NGX.DLSS.Quality 2

# Disable TSR (conflicts with DLSS)
r.TemporalAA.Upscaling 0
```

**Result:**

```
GPU: 100%+ â†’ 29% (-71%)
Concurrent users: 1 â†’ 4 per VM (4x)
Cost per user: -75%
```

### Challenge 2: Multi-User Session Management

**Problem:**

- Each user needs isolated UE instance
- Dynamic routing to available servers
- Session lifecycle management

**Solution: Matchmaker System**

```javascript
// Matchmaker logic
class SessionManager {
  async assignSession(userId) {
    // Find available Cirrus server
    const server = await this.findAvailableServer();

    if (!server) {
      // Spin up new container (future: Kakao Cloud API)
      server = await this.createNewServer();
    }

    // Create session
    const session = {
      userId,
      serverId: server.id,
      subdomain: `session-${Date.now()}.ps.domain.com`,
      startTime: Date.now(),
      maxDuration: 30 * 60 * 1000, // 30ë¶„
    };

    // Store in Redis
    await redis.setex(
      `session:${userId}`,
      1800, // 30ë¶„ TTL
      JSON.stringify(session),
    );

    return session;
  }

  async findAvailableServer() {
    const servers = await redis.smembers("cirrus:servers");

    for (const serverId of servers) {
      const load = await redis.get(`cirrus:${serverId}:load`);
      if (parseInt(load) < 4) {
        // Max 4 users per server
        return { id: serverId, load: parseInt(load) };
      }
    }

    return null;
  }
}
```

### Challenge 3: AI Product Recommendations

**Problem:**

- ìˆ˜ì²œ ê°œ ì œí’ˆ ì¤‘ ì‚¬ìš©ì ì˜ˆì‚°/ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì œí’ˆ ì¶”ì²œ
- ì‹¤ì‹œê°„ ê²€ìƒ‰ í•„ìš”
- ì •í™•ë„ì™€ ì†ë„ ê· í˜•

**Solution: RAG with Pinecone**

```python
# AI service (FastAPI)
from pinecone import Pinecone
from openai import OpenAI

class RecommendationService:
    def __init__(self):
        self.pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
        self.index = self.pc.Index('products')
        self.openai = OpenAI()

    async def recommend(self, query: str, budget: int, style: str):
        # Generate embedding
        embedding = self.openai.embeddings.create(
            model="text-embedding-3-small",
            input=query
        ).data[0].embedding

        # Search in vector DB
        results = self.index.query(
            vector=embedding,
            top_k=20,
            filter={
                "price": {"$lte": budget},
                "style": style
            },
            include_metadata=True
        )

        # Rerank with GPT-4
        context = "\n".join([
            f"{r.metadata['name']}: {r.metadata['description']}"
            for r in results.matches[:10]
        ])

        response = self.openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a professional consultant."},
                {"role": "user", "content": f"User query: {query}\nProducts:\n{context}\n\nRecommend top 3."}
            ]
        )

        return response.choices[0].message.content
```

**Result:**

- Sub-second response time
- 90%+ recommendation accuracy (user feedback)
- Scalable to 100K+ products

### Challenge 4: Zero-Downtime Deployment

**Problem:**

- Daily deploys needed
- Active streaming sessions must not disconnect
- Database migrations without downtime

**Solution: Blue-Green + Health Checks**

```yaml
# GitHub Actions
deploy:
  steps:
    - name: Start new container (blue)
      run: docker run -d --name app-blue ...

    - name: Health check
      run: |
        for i in {1..30}; do
          if curl -f http://localhost:3000/health; then
            break
          fi
          sleep 2
        done

    - name: Switch traffic
      run: docker exec nginx nginx -s reload

    - name: Stop old container (green)
      run: docker stop app-green
```

## ğŸ“Š Performance Metrics

### Infrastructure

| Metric                  | Target | Achieved | Status |
| ----------------------- | ------ | -------- | ------ |
| GPU Utilization         | <30%   | 29%      | âœ…     |
| Concurrent Users/VM     | 3+     | 4        | âœ…     |
| Streaming Latency       | <100ms | ~80ms    | âœ…     |
| API Response Time (p95) | <500ms | 320ms    | âœ…     |
| Uptime                  | 99.9%  | 99.95%   | âœ…     |

### Development

| Metric                   | Baseline | Result    | Status |
| ------------------------ | -------- | --------- | ------ |
| Deploy Frequency         | Manual   | 5-10/week | âœ…     |
| Deploy Time              | 30min    | 5min      | âœ…     |
| Mean Time to Recovery    | Hours    | <10min    | âœ…     |
| Bug Detection (pre-prod) | 60%      | 90%+      | âœ…     |

## ğŸ“ Key Learnings

### 1. Start Simple, Architect for Scale

Modular Monolithicìœ¼ë¡œ ì‹œì‘í•´ ë¹ ë¥´ê²Œ ì¶œì‹œí•˜ê³ , ëª…í™•í•œ ê²½ê³„ë¥¼ ìœ ì§€í•˜ë©´ì„œ MSA ì „í™˜ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.

### 2. Measure Before Optimize

GPU ë³‘ëª©ì€ "ë” ë§ì€ GPU"ê°€ ì•„ë‹ˆë¼ "FPS ì œí•œ"ìœ¼ë¡œ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸¡ì • ì—†ì´ëŠ” ì•Œ ìˆ˜ ì—†ì—ˆì„ ê²ƒì…ë‹ˆë‹¤.

### 3. Developer Experience = Velocity

- Prisma ORM: Type safety
- Feature-based modules: AI context ìµœì í™”
- Standardized patterns: ì˜¨ë³´ë”© ì‹œê°„ ë‹¨ì¶•

### 4. AI is Not Magic

RAG ì‹œìŠ¤í…œë„ ê²°êµ­ì€ ì˜ ì„¤ê³„ëœ vector search + prompt engineeringì…ë‹ˆë‹¤.

### 5. Infrastructure as Code

Docker, GitHub Actions, Nginx configsë¥¼ ì½”ë“œë¡œ ê´€ë¦¬í•˜ë©´ì„œ ì¬í˜„ ê°€ëŠ¥í•œ ë°°í¬ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ”® Future Improvements

### Short-term (Q1 2025)

- [ ] PM2 process management
- [ ] Dynamic VM provisioning (Kakao Cloud API)
- [ ] Enhanced monitoring (Grafana dashboards)
- [ ] Mobile app (React Native)

### Mid-term (Q2-Q3 2025)

- [ ] TypeScript migration
- [ ] MSA extraction (streaming service first)
- [ ] Kubernetes orchestration
- [ ] Multi-region deployment

### Long-term (Q4 2025+)

- [ ] Real-time collaboration
- [ ] VR/AR support
- [ ] Edge computing (CDN integration)
- [ ] ML model optimization

## ğŸ’¡ What Went Well

âœ… **Technical Decisions**

- Modular Monolithic: ë¹ ë¥¸ ê°œë°œ ì†ë„
- Prisma ORM: Type safetyë¡œ ëŸ°íƒ€ì„ ë²„ê·¸ ê°ì†Œ
- Docker: ì¼ê´€ëœ í™˜ê²½

âœ… **Performance**

- GPU ìµœì í™”: 4x capacity improvement
- Zero-downtime deploys: ì‹ ë¢°ë„ í–¥ìƒ
- Sub-100ms latency: ìš°ìˆ˜í•œ UX

âœ… **Team Productivity**

- Feature-based modules: ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
- Standardized patterns: ë¹ ë¥¸ ì˜¨ë³´ë”©
- AI-friendly structure: Claude/Copilot í™œìš©

## ğŸš§ What Could Be Better

âš ï¸ **Technical Debt**

- JavaScript â†’ TypeScript ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”
- Test coverage ë¶€ì¡± (í˜„ì¬ 60%, ëª©í‘œ 80%)
- Documentation ìë™í™” ë¯¸ë¹„

âš ï¸ **Infrastructure**

- Manual VM provisioning (ìë™í™” ì˜ˆì •)
- Single-region deployment (multi-region í•„ìš”)
- Monitoring gaps (ì¼ë¶€ ë©”íŠ¸ë¦­ ëˆ„ë½)

âš ï¸ **Process**

- Code review ì†ë„ ê°œì„  í•„ìš”
- Incident response playbook ë¯¸ë¹„
- Capacity planning ìˆ˜ë™

## ğŸ“š Related Documentation

- [Modular Monolithic Architecture](/docs/architecture/modular-monolithic)
- [Pixel Streaming Optimization](/docs/streaming/pixel-streaming-optimization)
- [Prisma ORM Patterns](/docs/best-practices/prisma-patterns)
- [Docker Deployment](/docs/infrastructure/docker-deployment)
- [Error Handling](/docs/best-practices/error-handling)

---

> "Ship fast, measure everything, iterate constantly.  
> Good architecture enables change, not prevents it."

**Project Status:** MVP launched, active users growing, continuous optimization ongoing.
